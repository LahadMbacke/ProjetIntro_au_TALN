{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/lahad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/lahad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "import spacy\n",
    "\n",
    "# Charger le modèle français de spacy\n",
    "nlp = spacy.load('fr_core_news_sm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation l'ensemble d'entraînement en 2 parties: entrainement et validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger les données\n",
    "# data = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "# train_data, val_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_data.to_csv(\"../data/train_split.csv\", index=False)\n",
    "# val_data.to_csv(\"../data/validation_split.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>titre</th>\n",
       "      <th>type</th>\n",
       "      <th>difficulte</th>\n",
       "      <th>cout</th>\n",
       "      <th>ingredients</th>\n",
       "      <th>recette</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recette_170277.xml</td>\n",
       "      <td>Langue de boeuf sauce piquante aux cornichons</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Facile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- 1 langue de 1,5 kg - 20 cl de vinaigre d'alc...</td>\n",
       "      <td>Faire tremper la langue toute une nuit dans un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recette_21519.xml</td>\n",
       "      <td>Tarte aux raisins et amandes</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Facile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- 1 pâte brisée - 150 g de raisins bien mûrs -...</td>\n",
       "      <td>Garnissez une tourtière avec la pâte étalée. F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recette_72746.xml</td>\n",
       "      <td>Meringues bien sèches</td>\n",
       "      <td>Dessert</td>\n",
       "      <td>Très facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 2 blancs d'oeufs - 60 g de sucre en poudre -...</td>\n",
       "      <td>Préchauffez le four à 150°, thermostat 5. Ajou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recette_38858.xml</td>\n",
       "      <td>Sandwich jambon, menthe et feta</td>\n",
       "      <td>Plat principal</td>\n",
       "      <td>Très facile</td>\n",
       "      <td>Moyen</td>\n",
       "      <td>- 3 tranches de pain complet ou de seigle ou d...</td>\n",
       "      <td>Faire la petit sauce à la menthe : mêler crème...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recette_167836.xml</td>\n",
       "      <td>Salade de mâche et lardons</td>\n",
       "      <td>Entrée</td>\n",
       "      <td>Très facile</td>\n",
       "      <td>Bon marché</td>\n",
       "      <td>- 300 g de mâche - quelques feuilles de roquet...</td>\n",
       "      <td>Faire revenir les lardons et les déposer chaud...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               doc_id                                          titre  \\\n",
       "0  recette_170277.xml  Langue de boeuf sauce piquante aux cornichons   \n",
       "1   recette_21519.xml                   Tarte aux raisins et amandes   \n",
       "2   recette_72746.xml                          Meringues bien sèches   \n",
       "3   recette_38858.xml                Sandwich jambon, menthe et feta   \n",
       "4  recette_167836.xml                     Salade de mâche et lardons   \n",
       "\n",
       "             type   difficulte        cout  \\\n",
       "0  Plat principal       Facile       Moyen   \n",
       "1         Dessert       Facile       Moyen   \n",
       "2         Dessert  Très facile  Bon marché   \n",
       "3  Plat principal  Très facile       Moyen   \n",
       "4          Entrée  Très facile  Bon marché   \n",
       "\n",
       "                                         ingredients  \\\n",
       "0  - 1 langue de 1,5 kg - 20 cl de vinaigre d'alc...   \n",
       "1  - 1 pâte brisée - 150 g de raisins bien mûrs -...   \n",
       "2  - 2 blancs d'oeufs - 60 g de sucre en poudre -...   \n",
       "3  - 3 tranches de pain complet ou de seigle ou d...   \n",
       "4  - 300 g de mâche - quelques feuilles de roquet...   \n",
       "\n",
       "                                             recette  \n",
       "0  Faire tremper la langue toute une nuit dans un...  \n",
       "1  Garnissez une tourtière avec la pâte étalée. F...  \n",
       "2  Préchauffez le four à 150°, thermostat 5. Ajou...  \n",
       "3  Faire la petit sauce à la menthe : mêler crème...  \n",
       "4  Faire revenir les lardons et les déposer chaud...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger les données\n",
    "train_data = pd.read_csv(\"../data/train_split.csv\")\n",
    "val_data = pd.read_csv(\"../data/validation_split.csv\")\n",
    "test_data = pd.read_csv(\"../data/test.csv\")\n",
    "\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistiques sur les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pourcentage de documents par classe dans chaque ensemble :\n",
      "Ensemble d'entraînement :\n",
      "type\n",
      "Plat principal    46.54\n",
      "Dessert           30.43\n",
      "Entrée            23.03\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Ensemble de validation :\n",
      "type\n",
      "Plat principal    46.41\n",
      "Dessert           29.10\n",
      "Entrée            24.49\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Ensemble de test :\n",
      "type\n",
      "Plat principal    46.40\n",
      "Dessert           29.32\n",
      "Entrée            24.28\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# # Nombre de documents dans chaque ensemble\n",
    "# num_train_docs = len(train_data)\n",
    "# num_val_docs = len(val_data)\n",
    "# num_test_docs = len(test_data)\n",
    "\n",
    "# print(\"Nombre de documents dans chaque ensemble :\")\n",
    "# print(\"Entraînement :\", num_train_docs)\n",
    "# print(\"Validation :\", num_val_docs)\n",
    "# print(\"Test :\", num_test_docs)\n",
    "\n",
    "# # Nombre de documents dans chaque ensemble pour chaque classe\n",
    "# train_label_counts = train_data['type'].value_counts()\n",
    "# val_label_counts = val_data['type'].value_counts()\n",
    "# test_label_counts = test_data['type'].value_counts()\n",
    "\n",
    "# print(\"\\nNombre de documents par classe dans chaque ensemble :\")\n",
    "# print(\"Ensemble d'entraînement :\")\n",
    "# print(train_label_counts)\n",
    "# print(\"\\nEnsemble de validation :\")\n",
    "# print(val_label_counts)\n",
    "# print(\"\\nEnsemble de test :\")\n",
    "# print(test_label_counts)\n",
    "\n",
    "# Pourcentage de documents dans chaque ensemble pour chaque classe\n",
    "train_label_percentages = (train_data['type'].value_counts(normalize=True) * 100).round(2)\n",
    "val_label_percentages = (val_data['type'].value_counts(normalize=True) * 100).round(2)\n",
    "test_label_percentages = (test_data['type'].value_counts(normalize=True) * 100).round(2)\n",
    "\n",
    "print(\"\\nPourcentage de documents par classe dans chaque ensemble :\")\n",
    "print(\"Ensemble d'entraînement :\")\n",
    "print(train_label_percentages)\n",
    "print(\"\\nEnsemble de validation :\")\n",
    "print(val_label_percentages)\n",
    "print(\"\\nEnsemble de test :\")\n",
    "print(test_label_percentages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separer les données en attributs et étiquettes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des données d'entraînement\n",
    "train_data['text'] = train_data['titre'] + \" \" + train_data['recette']\n",
    "train_data = train_data[['text', 'type']]\n",
    "\n",
    "# Prétraitement des données de validation\n",
    "val_data['text'] = val_data['titre'] + \" \" + val_data['recette']\n",
    "val_data = val_data[['text', 'type']]\n",
    "\n",
    "# Prétraitement des données de test\n",
    "test_data['text'] = test_data['titre'] + \" \" + test_data['recette']\n",
    "test_data = test_data[['text', 'type']]\n",
    "\n",
    "# Diviser les données en attributs et étiquettes\n",
    "X_train = train_data['text']\n",
    "y_train = train_data['type']\n",
    "X_val = val_data['text']\n",
    "y_val = val_data['type']\n",
    "X_test = test_data['text']\n",
    "y_test = test_data['type']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Nettoyage des donnees "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import FrenchStemmer\n",
    "\n",
    "stopwords_fr = set(stopwords.words('french'))\n",
    "stemmer = FrenchStemmer()\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "def clean_text(text):\n",
    "    # Tokenization and lowercase conversion\n",
    "    words = simple_preprocess(text, min_len=2)\n",
    "    words = [word for word in words if word not in stopwords_fr]\n",
    "    doc = nlp(\" \".join(words))\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    words = [token.lemma_ for token in doc]\n",
    "    \n",
    "    cleaned_text = ' '.join(words)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "# Appliquer le nettoyage sur les données \n",
    "X_train = X_train.apply(clean_text)\n",
    "X_val = X_val.apply(clean_text)\n",
    "X_test = X_test.apply(clean_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Test Data:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Dessert     0.3088    0.3194    0.3140       407\n",
      "        Entrée     0.2656    0.2522    0.2588       337\n",
      "Plat principal     0.4930    0.4953    0.4942       644\n",
      "\n",
      "      accuracy                         0.3847      1388\n",
      "     macro avg     0.3558    0.3557    0.3557      1388\n",
      "  weighted avg     0.3838    0.3847    0.3842      1388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Créer un classificateur baseline\n",
    "dummy = DummyClassifier(strategy='stratified', random_state=42)\n",
    "dummy.fit(X_train, y_train)\n",
    "\n",
    "# # Prédire sur les données de validation\n",
    "# y_pred_val = dummy.predict(X_val)\n",
    "\n",
    "# # Afficher le rapport de classification pour les données de developpement\n",
    "# print(\"Classification Report for Validation Data:\")\n",
    "# print(classification_report(y_val, y_pred_val))\n",
    "\n",
    "# Prédire sur les données de test\n",
    "y_pred_test = dummy.predict(X_test)\n",
    "\n",
    "# Afficher le rapport de classification pour les données de test\n",
    "print(\"Classification Report for Test Data:\")\n",
    "print(classification_report(y_test, y_pred_test,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run2: TF-IDF + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics sur les donnees de Test:\n",
      "Accuracy: 0.8731988472622478\n",
      "Precision: 0.8716080572000864\n",
      "Recall: 0.8731988472622478\n",
      "F1 Score: 0.8722572692756911\n",
      "Confusion Matrix:\n",
      "[[405   1   1]\n",
      " [  2 244  91]\n",
      " [  5  76 563]]\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Dessert      0.983     0.995     0.989       407\n",
      "        Entrée      0.760     0.724     0.742       337\n",
      "Plat principal      0.860     0.874     0.867       644\n",
      "\n",
      "      accuracy                          0.873      1388\n",
      "     macro avg      0.868     0.864     0.866      1388\n",
      "  weighted avg      0.872     0.873     0.872      1388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorisation des textes\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf.transform(X_val)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Création du modèle SVM avec noyau gaussien (RBF)\n",
    "svm_rbf = SVC(kernel='rbf', C=5, random_state=42)\n",
    "\n",
    "\n",
    "# Entraînement du modèle\n",
    "svm_rbf.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Prédiction sur les données de developpement\n",
    "# y_pred_val = svm_rbf.predict(X_val_tfidf)\n",
    "\n",
    "# # Evaluation sur les données de developpement\n",
    "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "# precision_val = precision_score(y_val, y_pred_val, average='weighted')\n",
    "# recall_val = recall_score(y_val, y_pred_val, average='weighted')\n",
    "# f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "# conf_matrix_val = confusion_matrix(y_val, y_pred_val)\n",
    "# class_report_val = classification_report(y_val, y_pred_val,digits=3)\n",
    "\n",
    "# Affichage des résultats sur les données de developpement\n",
    "# print(\"Evaluation Metrics sur les donnees de developpement:\")\n",
    "# print(f\"Accuracy: {accuracy_val}\")\n",
    "# print(f\"Precision: {precision_val}\")\n",
    "# print(f\"Recall: {recall_val}\")\n",
    "# print(f\"F1 Score: {f1_val}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix_val)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report_val)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "y_pred_test = svm_rbf.predict(X_test_tfidf)\n",
    "\n",
    "# Evaluation sur les données de test\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "class_report_test = classification_report(y_test, y_pred_test,digits=3)\n",
    "\n",
    "# Affichage des résultats sur les données de test\n",
    "print(\"\\nEvaluation Metrics sur les donnees de Test:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1 Score: {f1_test}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_test)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run3: Word2Vec + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics sur les donnees de Test:\n",
      "Accuracy: 0.8681556195965417\n",
      "Precision: 0.8658581742307588\n",
      "Recall: 0.8681556195965417\n",
      "F1 Score: 0.8648599185905296\n",
      "Confusion Matrix:\n",
      "[[403   2   2]\n",
      " [  3 220 114]\n",
      " [  4  58 582]]\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Dessert      0.983     0.990     0.987       407\n",
      "        Entrée      0.786     0.653     0.713       337\n",
      "Plat principal      0.834     0.904     0.867       644\n",
      "\n",
      "      accuracy                          0.868      1388\n",
      "     macro avg      0.867     0.849     0.856      1388\n",
      "  weighted avg      0.866     0.868     0.865      1388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Modèle Word2Vec\n",
    "corpus = [sentence.split() for sentence in X_train]\n",
    "word2vec_model = Word2Vec(corpus, vector_size=150, window=10, min_count=1, workers=1, sg=1)\n",
    "\n",
    "# Calcul des vecteurs de mots moyens pour chaque document\n",
    "def document_vector(word2vec_model, doc):\n",
    "    \"\"\"Calculer le vecteur moyen pour un document en utilisant les vecteurs de mots Word2Vec\"\"\"\n",
    "    # Filtrer les mots absents dans le vocabulaire\n",
    "    doc = [word for word in doc if word in word2vec_model.wv.key_to_index]\n",
    "    if len(doc) != 0:\n",
    "        return np.mean(word2vec_model.wv[doc], axis=0)\n",
    "    else:\n",
    "        return np.zeros(word2vec_model.vector_size)\n",
    "\n",
    "# Préparation des données de test pour Word2Vec\n",
    "X_train_word2vec = np.array([document_vector(word2vec_model, doc.split()) for doc in X_train])\n",
    "X_val_word2vec = np.array([document_vector(word2vec_model, doc.split()) for doc in X_val])\n",
    "X_test_word2vec = np.array([document_vector(word2vec_model, doc.split()) for doc in X_test])\n",
    "\n",
    "# Modèle SVM\n",
    "svm_classifier = SVC(kernel='rbf', C=5, random_state=42)\n",
    "svm_classifier.fit(X_train_word2vec, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "y_pred_test = svm_classifier.predict(X_test_word2vec)\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "class_report_test = classification_report(y_test, y_pred_test,digits=3)\n",
    "\n",
    "print(\"\\nEvaluation Metrics sur les donnees de Test:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1 Score: {f1_test}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_test)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_test)\n",
    "\n",
    "\n",
    "# # Evaluation\n",
    "# Prédiction sur les données de developpement\n",
    "# y_pred_val = svm_classifier.predict(X_val_word2vec)\n",
    "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "# precision_val = precision_score(y_val, y_pred_val, average='weighted')\n",
    "# recall_val = recall_score(y_val, y_pred_val, average='weighted')\n",
    "# f1_val = f1_score(y_val, y_pred_val, average='weighted')\n",
    "# conf_matrix_val = confusion_matrix(y_val, y_pred_val)\n",
    "# class_report_val = classification_report(y_val, y_pred_val,digits=4)\n",
    "# Affichage des résultats\n",
    "# print(\"Evaluation Metrics sur les donnees de  developpement :\")\n",
    "# print(f\"Accuracy: {accuracy_val}\")\n",
    "# print(f\"Precision: {precision_val}\")\n",
    "# print(f\"Recall: {recall_val}\")\n",
    "# print(f\"F1 Score: {f1_val}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix_val)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run4: CountVectorizer + SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics sur les donnees de Tests:\n",
      "Accuracy: 0.8652737752161384\n",
      "Precision: 0.8628157915033674\n",
      "Recall: 0.8652737752161384\n",
      "F1 Score: 0.863688358799296\n",
      "Confusion Matrix:\n",
      "[[404   1   2]\n",
      " [  5 235  97]\n",
      " [  6  76 562]]\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "       Dessert      0.973     0.993     0.983       407\n",
      "        Entrée      0.753     0.697     0.724       337\n",
      "Plat principal      0.850     0.873     0.861       644\n",
      "\n",
      "      accuracy                          0.865      1388\n",
      "     macro avg      0.859     0.854     0.856      1388\n",
      "  weighted avg      0.863     0.865     0.864      1388\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Vectorisation des textes\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# Transformation des données textuelles en vecteurs de compte\n",
    "X_train_counts = vectorizer.fit_transform(X_train)\n",
    "X_val_counts = vectorizer.transform(X_val)\n",
    "X_test_counts = vectorizer.transform(X_test)\n",
    "\n",
    "# Création et entraînement du modèle SVM\n",
    "svm_classifier = SVC(kernel=\"rbf\", C=10, random_state=42)\n",
    "svm_classifier.fit(X_train_counts, y_train)\n",
    "\n",
    "# Prédiction sur les données de test\n",
    "y_pred_test = svm_classifier.predict(X_test_counts)\n",
    "\n",
    "# Evaluation sur les données de test\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "precision_test = precision_score(y_test, y_pred_test, average='weighted')\n",
    "recall_test = recall_score(y_test, y_pred_test, average='weighted')\n",
    "f1_test = f1_score(y_test, y_pred_test, average='weighted')\n",
    "conf_matrix_test = confusion_matrix(y_test, y_pred_test)\n",
    "class_report_test = classification_report(y_test, y_pred_test,digits=3)\n",
    "\n",
    "# Affichage des résultats sur les données de test\n",
    "print(\"\\nEvaluation Metrics sur les donnees de Tests:\")\n",
    "print(f\"Accuracy: {accuracy_test}\")\n",
    "print(f\"Precision: {precision_test}\")\n",
    "print(f\"Recall: {recall_test}\")\n",
    "print(f\"F1 Score: {f1_test}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix_test)\n",
    "print(\"Classification Report:\")\n",
    "print(class_report_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Prédiction sur les données de developpement\n",
    "# y_pred_val = svm_classifier.predict(X_val_counts)\n",
    "\n",
    "# # Evaluation sur les données de developpement\n",
    "# accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "# precision_val = precision_score(y_val, y_pred_val, average='weighted')\n",
    "# recall_val = recall_score(y_val, y_pred_val, average='weighted')\n",
    "# f1_val = f1_score(y_val, y_pred_val, average='macro')\n",
    "# conf_matrix_val = confusion_matrix(y_val, y_pred_val)\n",
    "# class_report_val = classification_report(y_val, y_pred_val,digits=4)\n",
    "\n",
    "# # Affichage des résultats sur les données de developpement\n",
    "# print(\"Evaluation Metrics sur les donnees de developpement :\")\n",
    "# print(f\"Accuracy: {accuracy_val}\")\n",
    "# print(f\"Precision: {precision_val}\")\n",
    "# print(f\"Recall: {recall_val}\")\n",
    "# print(f\"F1 Score: {f1_val}\")\n",
    "# print(\"Confusion Matrix:\")\n",
    "# print(conf_matrix_val)\n",
    "# print(\"Classification Report:\")\n",
    "# print(class_report_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# parameters = {'kernel':('linear', 'rbf'), 'C':[1,10]}\n",
    "# svc = SVC(random_state=42)\n",
    "# clf = GridSearchCV(svc, parameters)\n",
    "# clf.fit(X_train_tfidf, y_train)\n",
    "# #Print the best parameters\n",
    "# print(\"Best parameters: \", clf.best_params_)\n",
    "# # Use the best estimator to make predictions\n",
    "# y_pred = clf.best_estimator_.predict(X_test_tfidf)\n",
    "\n",
    "# # Evaluation\n",
    "# print(classification_report(y_testt, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
